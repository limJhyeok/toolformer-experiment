{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/toolformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "tokenizer_config.json: 100%|██████████| 619/619 [00:00<00:00, 1.60MB/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 1.77MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.35MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.37M/1.37M [00:00<00:00, 6.13MB/s]\n",
      "added_tokens.json: 100%|██████████| 4.04k/4.04k [00:00<00:00, 14.2MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 357/357 [00:00<00:00, 1.24MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "config.json: 100%|██████████| 930/930 [00:00<00:00, 3.02MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 24.2G/24.2G [02:20<00:00, 173MB/s] \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to add calls to a Calendar API to a piece of text.\n",
    "The API calls should help you get information required to complete the text.\n",
    "You can call the API by writing \"[Calendar()]\"\n",
    "Here are some examples of API calls:\n",
    "Input: Today is the first Friday of the year.\n",
    "Output: Today is the first [Calendar()] Friday of the year.\n",
    "Input: The president of the United States is Joe Biden.\n",
    "Output: The president of the United States is [Calendar()] Joe Biden.\n",
    "Input: [input]\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "data = [\n",
    "    \"The store is never open on the weekend, so today it is closed.\",\n",
    "    \"The number of days from now until Christmas is 30\",\n",
    "    \"The current day of the week is Wednesday.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "DEFAULT_PROMPT_INPUT_TAG = '[input]'\n",
    "prompt_input_tag_regex = re.escape(DEFAULT_PROMPT_INPUT_TAG)\n",
    "data_string = data[idx]\n",
    "data_with_prompt = re.sub(prompt_input_tag_regex, data_string, prompt)\n",
    "token_ids = tokenizer(data_with_prompt, return_tensors = 'pt')\n",
    "\n",
    "batch_size, len_prev = token_ids['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "  output = model.generate(**token_ids, max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The store is never open on the [Calendar()] weekend, so today it is closed.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0][len_prev:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call with argument: no argument,\n",
      "result: Today is Thursday, November 30, 2023.\n"
     ]
    }
   ],
   "source": [
    "from tools import Calendar\n",
    "print(f\"API call with argument: no argument,\\nresult: {Calendar()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with the API call\n",
      "'The store is never open on the [Calendar() -> Today is Thursday, November 30, 2023.] weekend, so today it is closed.'\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text with the API call\\n'The store is never open on the [Calendar() -> {Calendar()}] weekend, so today it is closed.'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문맥상 api 결과가 주말이여야 더 그럴듯하므로 변경\n",
    "including_API_with_result ='The store is never open on the [Calendar() -> Today is Saturday, November 25, 2023.]' \n",
    "including_API_without_result = 'The store is never open on the [Calendar()]'\n",
    "plain_text = 'The store is never open on the'\n",
    "\n",
    "next_words = 'weekend, so today it is closed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt[:-16] + including_API_with_result + next_words, return_tensors = 'pt')\n",
    "mask_tokens = tokenizer(prompt[:-16] + including_API_with_result, return_tensors = 'pt')\n",
    "batch_size, len_mask_tokens = mask_tokens['input_ids'].size()\n",
    "\n",
    "labels = tokenizer(prompt[:-16] + including_API_with_result + next_words, return_tensors = \"pt\")['input_ids']\n",
    "labels[:, :len_mask_tokens] = -100\n",
    "with torch.no_grad():\n",
    "  api_with_result_output = model(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt[:-16] + including_API_without_result + next_words, return_tensors = 'pt')\n",
    "mask_tokens = tokenizer(prompt[:-16] + including_API_without_result, return_tensors = 'pt')\n",
    "batch_size, len_mask_tokens = mask_tokens['input_ids'].size()\n",
    "\n",
    "labels = tokenizer(prompt[:-16] + including_API_without_result + next_words, return_tensors = \"pt\")['input_ids']\n",
    "labels[:, :len_mask_tokens] = -100\n",
    "with torch.no_grad():\n",
    "  api_without_result_output = model(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt[:-16] + plain_text + next_words, return_tensors = 'pt')\n",
    "mask_tokens = tokenizer(prompt[:-16] + plain_text, return_tensors = 'pt')\n",
    "batch_size, len_mask_tokens = mask_tokens['input_ids'].size()\n",
    "\n",
    "labels = tokenizer(prompt[:-16] + plain_text + next_words, return_tensors = \"pt\")['input_ids']\n",
    "labels[:, :len_mask_tokens] = -100\n",
    "with torch.no_grad():\n",
    "  plain_output = model(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api + result loss: 3.0480871200561523\n",
      "api without result loss: 2.9808812141418457\n",
      "plain text loss: 3.553638458251953\n"
     ]
    }
   ],
   "source": [
    "print(f\"api + result loss: {api_with_result_output.loss}\")\n",
    "print(f\"api without result loss: {api_without_result_output.loss}\")\n",
    "print(f\"plain text loss: {plain_output.loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_threshold = 1.0\n",
    "if api_with_result_output.loss > min(api_without_result_output, plain_output) + filtering_threshold:\n",
    "  finetune_dataset = including_API_without_result + next_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
